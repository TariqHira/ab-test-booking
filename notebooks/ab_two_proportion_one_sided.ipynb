{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a904b597",
   "metadata": {},
   "source": [
    "\n",
    "# A/B Test Sample Size Notebook — One-Sided Two-Proportion Z-Test (H1: p2 > p1)\n",
    "\n",
    "This notebook helps you design and visualize a one-sided A/B test for conversion rates where the\n",
    "alternative hypothesis is that the treatment is better than control (H1: p2 > p1).\n",
    "\n",
    "What you get:\n",
    "- Per-group sample size via:\n",
    "  - Manual raw pooled proportions formula\n",
    "  - Manual Cohen’s h formula\n",
    "  - statsmodels power solver\n",
    "- MDE can be absolute (e.g., +0.02) or relative (e.g., +10% uplift of p1)\n",
    "- Visuals to build intuition:\n",
    "  - Sample size vs. MDE (absolute)\n",
    "  - Cohen’s h vs. baseline for a fixed absolute lift\n",
    "  - Power vs. per-group sample size (n)\n",
    "\n",
    "Every line of code includes comments explaining what the code does and why (the concept).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97beeaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Imports & Power Solver\n",
    "# ============================================================\n",
    "\n",
    "import math                          # math functions (sqrt, asin) for manual formulas\n",
    "import numpy as np                   # arrays & vectorized math for simulations/plots\n",
    "import matplotlib.pyplot as plt      # visualization (matplotlib only; no seaborn)\n",
    "\n",
    "# statsmodels: power analysis engine for common tests\n",
    "from statsmodels.stats.power import NormalIndPower          # solves for n, power, or effect\n",
    "from statsmodels.stats.proportion import proportion_effectsize  # computes Cohen's h given p1, p2\n",
    "\n",
    "# Try to import accurate Normal quantiles; fall back if SciPy isn't available\n",
    "try:\n",
    "    from scipy.stats import norm                              # normal distribution utilities (ppf = inverse CDF)\n",
    "    def z_quantile(prob):                                     # helper to get z so that P(Z<=z)=prob for Z~N(0,1)\n",
    "        return norm.ppf(prob)                                 # precise quantile from SciPy\n",
    "except Exception:\n",
    "    def z_quantile(p):                                        # approximate inverse CDF for standard normal\n",
    "        return math.sqrt(2) * math.erfinv(2*p - 1)            # decent approximation; SciPy recommended for accuracy\n",
    "\n",
    "# Instantiate a single power solver (reused to avoid reallocation)\n",
    "POWER_SOLVER = NormalIndPower()                               # engine implementing normal-approx power formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6149eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Core Functions: p2 from MDE, Sample Size Formulas, Wrapper\n",
    "# ============================================================\n",
    "\n",
    "def resolve_p2_from_mde(p1, mde, mde_type=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Determine p2 from baseline p1 and an MDE specification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1 : float in (0,1)                # baseline conversion rate (historical estimate)\n",
    "    mde : float                         # minimal uplift worth detecting (abs diff or relative)\n",
    "    mde_type : 'absolute'|'relative'    # interpretation of mde (Delta p vs. % uplift of p1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p2 : float in (0,1)                 # treatment conversion rate implied by MDE\n",
    "    \"\"\"\n",
    "    # Concept: MDE is a business decision -> the smallest effect worth acting on.\n",
    "    if mde_type == \"absolute\":                                 # e.g., +0.02 means +2 percentage points\n",
    "        p2 = p1 + mde                                          # absolute difference target\n",
    "    elif mde_type == \"relative\":                               # e.g., +0.10 means +10% uplift *of p1*\n",
    "        p2 = p1 * (1 + mde)                                    # relative increase target\n",
    "    else:\n",
    "        raise ValueError(\"mde_type must be 'absolute' or 'relative'\")  # guard against typos\n",
    "\n",
    "    # Numerical safety: avoid exact 0 or 1 (variance terms break at boundaries)\n",
    "    return float(np.clip(p2, 1e-8, 1 - 1e-8))                  # keep inside open interval (0,1)\n",
    "\n",
    "\n",
    "def n_per_group_raw(p1, p2, alpha=0.05, power=0.80):\n",
    "    \"\"\"\n",
    "    One-sided two-proportion z-test (equal n per group), manual closed form using\n",
    "    z_{1-alpha} for one-sided tests:\n",
    "\n",
    "    n ~= [ z_{1-alpha} * sqrt(2 * p * (1 - p)) + z_{1-beta} * sqrt(p1(1 - p1) + p2(1 - p2)) ]^2 / (p1 - p2)^2\n",
    "\n",
    "    where p = (p1 + p2)/2 is the pooled proportion.\n",
    "\n",
    "    Concepts:\n",
    "    - z_{1-alpha} (one-sided) controls Type I error in a single tail (H1: p2 > p1).\n",
    "    - z_{1-beta} targets the desired Power = 1-beta (prob of detecting the effect).\n",
    "    - Pooled term reflects H0 assumption (same rate), stabilizing variance estimate.\n",
    "    \"\"\"\n",
    "    z_alpha_one_sided = z_quantile(1 - alpha)                  # one-sided cutoff for significance level alpha\n",
    "    z_power        = z_quantile(power)                         # cutoff that delivers desired power 1-beta\n",
    "    p_pool         = 0.5 * (p1 + p2)                           # pooled conversion rate under H0 assumption\n",
    "    term_null      = math.sqrt(2 * p_pool * (1 - p_pool))      # variability under null (pooled)\n",
    "    term_alt       = math.sqrt(p1*(1 - p1) + p2*(1 - p2))      # variability under alternative (true p1, p2)\n",
    "    diff           = abs(p2 - p1)                              # effect magnitude we want to detect\n",
    "    n              = ((z_alpha_one_sided*term_null + z_power*term_alt) ** 2) / (diff ** 2)  # closed-form n\n",
    "    return n                                                   # per-group sample size (float; round up in planning)\n",
    "\n",
    "\n",
    "def cohens_h(p1, p2):\n",
    "    \"\"\"\n",
    "    Cohen's h = 2 * (arcsin(sqrt(p1)) - arcsin(sqrt(p2))).\n",
    "\n",
    "    Concept:\n",
    "    - arcsin(sqrt(.)) variance-stabilizing transform on [0,1].\n",
    "    - Equal absolute differences near 0.5 \"weigh more\" than near 0 or 1.\n",
    "    \"\"\"\n",
    "    return 2.0 * (math.asin(math.sqrt(p1)) - math.asin(math.sqrt(p2)))  # signed effect; take abs for magnitude\n",
    "\n",
    "\n",
    "def n_per_group_h(p1, p2, alpha=0.05, power=0.80):\n",
    "    \"\"\"\n",
    "    Approx per-group n using Cohen's h for two independent proportions (equal n),\n",
    "    one-sided test uses z_{1-alpha} instead of z_{1-alpha/2}:\n",
    "\n",
    "    n ~= 2 * (z_{1-alpha} + z_{1-beta})^2 / h^2\n",
    "    \"\"\"\n",
    "    z_alpha_one_sided = z_quantile(1 - alpha)                  # one-sided critical\n",
    "    z_power        = z_quantile(power)                         # z for achieving target power\n",
    "    h              = abs(cohens_h(p1, p2))                     # standardized effect magnitude (positive)\n",
    "    n              = 2.0 * ((z_alpha_one_sided + z_power) ** 2) / (h ** 2)  # closed-form using h\n",
    "    return n                                                   # per-group sample size (float)\n",
    "\n",
    "\n",
    "def n_per_group_statsmodels(p1, p2, alpha=0.05, power=0.80, alternative=\"larger\"):\n",
    "    \"\"\"\n",
    "    Per-group n solved by statsmodels NormalIndPower.\n",
    "    Internally converts (p1, p2) -> Cohen's h (via proportion_effectsize).\n",
    "\n",
    "    Parameters:\n",
    "    - alternative: for one-sided H1: p2 > p1, use 'larger'.\n",
    "    \"\"\"\n",
    "    effect_size = proportion_effectsize(p1, p2)                # compute Cohen's h from raw proportions\n",
    "    n = POWER_SOLVER.solve_power(effect_size=abs(effect_size), # solve for n (per group) given effect & targets\n",
    "                                 alpha=alpha,                  # significance level (Type I error control)\n",
    "                                 power=power,                  # desired power (1-beta)\n",
    "                                 ratio=1.0,                    # equal group sizes (optimal)\n",
    "                                 alternative=alternative)      # 'larger' for one-sided p2 > p1\n",
    "    return n                                                   # per-group sample size (float)\n",
    "\n",
    "\n",
    "def compute_sample_sizes(p1, mde, mde_type=\"absolute\", alpha=0.05, power=0.80, alternative=\"larger\"):\n",
    "    \"\"\"\n",
    "    Convenience wrapper that:\n",
    "    - Resolves p2 from p1 + MDE\n",
    "    - Returns a dict with all sample size methods + recommended ceil (one-sided design)\n",
    "    \"\"\"\n",
    "    p2 = resolve_p2_from_mde(p1, mde, mde_type=mde_type)       # translate business MDE into a target p2\n",
    "    n_raw      = n_per_group_raw(p1, p2, alpha=alpha, power=power)        # manual pooled-variance formula\n",
    "    n_h        = n_per_group_h(p1, p2, alpha=alpha, power=power)          # manual Cohen's h formula\n",
    "    n_sm       = n_per_group_statsmodels(p1, p2, alpha=alpha, power=power, alternative=alternative)  # statsmodels\n",
    "    n_reco     = math.ceil(max(n_raw, n_h, n_sm))              # planning tip: choose the max and round UP\n",
    "    return {\"p1\": p1, \"p2\": p2, \"alpha\": alpha, \"power\": power, \"alternative\": alternative,\n",
    "            \"n_raw\": n_raw, \"n_h\": n_h, \"n_statsmodels\": n_sm, \"n_recommended_per_group\": n_reco}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3467ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Visualization Helpers (Matplotlib only; one plot per figure)\n",
    "# ============================================================\n",
    "\n",
    "def plot_n_vs_mde(p1, alpha=0.05, power=0.80, mde_min=0.005, mde_max=0.10, points=60):\n",
    "    \"\"\"\n",
    "    Plot how per-group n explodes as MDE shrinks (absolute MDE).\n",
    "    Concept: Detecting tiny effects requires large samples — business tradeoff.\n",
    "    \"\"\"\n",
    "    mdes = np.linspace(mde_min, mde_max, points)               # grid of absolute MDEs (e.g., 0.5pp -> 10pp)\n",
    "    n_raw_curve, n_h_curve = [], []                            # containers for each method's n\n",
    "\n",
    "    for m in mdes:                                             # iterate over MDE values\n",
    "        p2 = resolve_p2_from_mde(p1, m, mde_type=\"absolute\")   # convert abs MDE to p2\n",
    "        n_raw_curve.append(n_per_group_raw(p1, p2, alpha, power))     # compute raw formula n\n",
    "        n_h_curve.append(n_per_group_h(p1, p2, alpha, power))         # compute h-based n\n",
    "\n",
    "    plt.figure(figsize=(8, 5))                                 # single figure, readable size\n",
    "    plt.plot(mdes*100, n_raw_curve, label=\"Manual Raw (pooled)\")      # plot raw curve vs % points\n",
    "    plt.plot(mdes*100, n_h_curve, linestyle=\"--\", label=\"Manual Cohen's h\")  # plot h curve dashed\n",
    "    plt.xlabel(\"MDE (absolute percentage points)\")             # x-axis explains unit (pp)\n",
    "    plt.ylabel(\"Per-group sample size (n)\")                    # y-axis is the metric of interest\n",
    "    plt.title(f\"Sample Size vs. MDE (Baseline p1={p1:.0%}, alpha={alpha}, Power={power}, one-sided)\")  # title\n",
    "    plt.legend()                                               # legend to distinguish curves\n",
    "    plt.grid(True, alpha=0.3)                                  # light grid for readability\n",
    "    plt.tight_layout()                                         # tidy layout to avoid cut-offs\n",
    "    plt.show()                                                 # render the plot\n",
    "\n",
    "\n",
    "def plot_h_vs_baseline(abs_diff=0.05, p1_min=0.05, p1_max=0.95, points=200):\n",
    "    \"\"\"\n",
    "    Show how the same absolute difference maps to different standardized effect sizes (h)\n",
    "    across baselines — the nonlinearity on the 0–1 probability scale.\n",
    "\n",
    "    Concept: 5pp at 10% is a much larger standardized shift than 5pp at 90%.\n",
    "    \"\"\"\n",
    "    p1_grid = np.linspace(p1_min, p1_max, points)              # grid of baselines\n",
    "    h_vals  = []                                               # holder for |h| magnitudes\n",
    "\n",
    "    for p1 in p1_grid:                                         # loop over baselines\n",
    "        p2 = resolve_p2_from_mde(p1, abs_diff, \"absolute\")     # apply fixed absolute difference\n",
    "        h_vals.append(abs(cohens_h(p1, p2)))                   # compute |h| and store\n",
    "\n",
    "    plt.figure(figsize=(8, 5))                                 # single figure\n",
    "    plt.plot(p1_grid*100, h_vals)                              # plot |h| vs baseline (%)\n",
    "    plt.xlabel(\"Baseline p1 (%)\")                              # x-label in percent to be intuitive\n",
    "    plt.ylabel(\"Cohen's h (|standardized effect|)\")            # y-label explains metric\n",
    "    plt.title(f\"Cohen's h vs Baseline (Absolute diff = {abs_diff*100:.1f} pp)\")  # informative title\n",
    "    plt.grid(True, alpha=0.3)                                  # subtle grid\n",
    "    plt.tight_layout()                                         # tidy layout\n",
    "    plt.show()                                                 # render the plot\n",
    "\n",
    "\n",
    "def plot_power_vs_n(p1, mde, mde_type=\"absolute\", alpha=0.05,\n",
    "                    n_min=50, n_max=5000, step=50,\n",
    "                    alternative=\"larger\", target_power=0.80):\n",
    "    \"\"\"\n",
    "    Plot statistical power as a function of per-group sample size (n)\n",
    "    for a two-proportion z-test, keeping p1/p2 (i.e., the effect) fixed.\n",
    "\n",
    "    Concept:\n",
    "    - Power rises with n: more data -> easier to detect the same true effect.\n",
    "    - This curve helps choose a practical n that meets your power target.\n",
    "    - One-sided: 'alternative' should be 'larger' for H1: p2 > p1.\n",
    "    \"\"\"\n",
    "    p2 = resolve_p2_from_mde(p1, mde, mde_type=mde_type)       # fix effect by resolving p2\n",
    "    h = proportion_effectsize(p1, p2)                          # convert raw proportions into Cohen's h\n",
    "    n_grid = np.arange(n_min, n_max + 1, step)                 # candidate per-group sample sizes\n",
    "\n",
    "    powers = []                                                # store power for each n\n",
    "    for n in n_grid:                                           # iterate over grid\n",
    "        pwr = POWER_SOLVER.power(effect_size=abs(h),           # magnitude of effect (Cohen's h)\n",
    "                                 nobs1=n,                      # per-group sample size\n",
    "                                 alpha=alpha,                  # Type I error rate\n",
    "                                 ratio=1.0,                    # equal group sizes\n",
    "                                 alternative=alternative)      # 'larger' for one-sided H1\n",
    "        powers.append(pwr)                                     # collect computed power\n",
    "\n",
    "    plt.figure(figsize=(8, 5))                                 # single chart\n",
    "    plt.plot(n_grid, powers, label=\"Power vs. per-group n\")    # power curve\n",
    "    plt.axhline(y=target_power, linestyle=\"--\",                # reference line at target power\n",
    "                label=f\"Target power = {target_power:.2f}\")\n",
    "    plt.xlabel(\"Per-group sample size (n)\")                    # x-axis label\n",
    "    plt.ylabel(\"Power (1 - beta)\")                             # y-axis label\n",
    "    p2_pct = f\"{p2:.0%}\"                                       # pretty p2 percentage for title\n",
    "    plt.title(f\"Power Curve (p1={p1:.0%}, p2={p2_pct}, alpha={alpha}, one-sided)\")  # informative title\n",
    "    plt.grid(True, alpha=0.3)                                  # readability\n",
    "    plt.legend()                                               # legend\n",
    "    plt.tight_layout()                                         # tidy layout\n",
    "    plt.show()                                                 # render\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942311c",
   "metadata": {},
   "source": [
    "## Configure & Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f81f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION (EDIT THESE)\n",
    "# ============================================================\n",
    "p1_cfg       = 0.10            # baseline conversion (e.g., 10%)\n",
    "mde_cfg      = 0.05            # desired MDE: if 'absolute' -> 0.05 = +5 percentage points\n",
    "mde_type_cfg = \"absolute\"      # 'absolute' or 'relative' (e.g., 0.05 = +5% uplift of p1 if 'relative')\n",
    "alpha_cfg    = 0.05            # significance level (one-sided uses z_{1-alpha})\n",
    "power_cfg    = 0.80            # desired power\n",
    "alt_cfg      = \"larger\"        # ONE-SIDED: H1: p2 > p1 -> use 'larger'\n",
    "\n",
    "# ============================================================\n",
    "# RUN: compute sample sizes & show visuals\n",
    "# ============================================================\n",
    "results = compute_sample_sizes(p1=p1_cfg, mde=mde_cfg, mde_type=mde_type_cfg,\n",
    "                               alpha=alpha_cfg, power=power_cfg, alternative=alt_cfg)  # compute all methods\n",
    "\n",
    "# Report results (planning tip: round UP per group)\n",
    "print(\"=== DESIGN INPUTS ===\")                               # header for clarity\n",
    "print(f\"Baseline p1:            {results['p1']:.4f}\")        # echo p1\n",
    "print(f\"Treatment p2 (target):  {results['p2']:.4f}\")        # implied p2 from MDE\n",
    "print(f\"Alpha:                  {results['alpha']}\")         # alpha shown explicitly\n",
    "print(f\"Power:                  {results['power']}\")         # power shown explicitly\n",
    "print(f\"Alternative:            {results['alternative']}\")   # one-sided vs two-sided\n",
    "\n",
    "print(\"\\n=== PER-GROUP SAMPLE SIZE (n) ===\")                 # header\n",
    "print(f\"Manual: Raw pooled      {results['n_raw']:.2f}\")     # manual raw formula\n",
    "print(f\"Manual: Cohen's h       {results['n_h']:.2f}\")       # manual h formula\n",
    "print(f\"statsmodels (h inside)  {results['n_statsmodels']:.2f}\")  # statsmodels solver\n",
    "print(f\"\\nRECOMMENDED (ceil max): {results['n_recommended_per_group']} per group\")  # conservative pick\n",
    "\n",
    "# Visual 1: Sample size vs absolute MDE (intuition on trade-offs)\n",
    "plot_n_vs_mde(p1=p1_cfg, alpha=alpha_cfg, power=power_cfg, mde_min=0.005, mde_max=0.10, points=60)  # curve\n",
    "\n",
    "# Visual 2: Cohen's h vs baseline for a fixed absolute difference\n",
    "plot_h_vs_baseline(abs_diff=0.05, p1_min=0.05, p1_max=0.95, points=200)  # nonlinearity demo\n",
    "\n",
    "# Visual 3: Power vs n (for your one-sided H1: p2 > p1)\n",
    "plot_power_vs_n(p1=p1_cfg, mde=mde_cfg, mde_type=mde_type_cfg,\n",
    "                alpha=alpha_cfg, n_min=50, n_max=5000, step=50,\n",
    "                alternative=alt_cfg, target_power=power_cfg)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
